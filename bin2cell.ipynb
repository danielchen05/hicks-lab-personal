{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook provides a tutorial of bin2cell. (worked with annData extensively)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**bin2cell**: aggregate 2um bins into single cells using DAPI/mCherry/GFP cell segmentation\n",
    "https://github.com/Teichlab/bin2cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "proposes 2um bin to cell groupings based on segmentation, which can be done on the morphology image and/or a visualisation of the gene expression.  \n",
    "End result: object with cells, created from grouped 2um bins assigned to the same object after segmentation.  \n",
    "The following code is looking at their demo notebook: https://nbviewer.org/github/Teichlab/bin2cell/blob/main/notebooks/demo.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "transport.py (219): Blowfish has been deprecated and will be removed in a future release\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import scanpy as sc\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import bin2cell as b2c\n",
    "\n",
    "#create directory for stardist input/output files\n",
    "os.makedirs(\"stardist\", exist_ok=True)\n",
    "\n",
    "# IDEA: 2um resolution is sub-cellular, can be used for recreating cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It starts by correcting for a novel technical effect in the data in variable bin dimensions, and then proposes a bin to cell assignment based on image segmentation. The result is an object with putative cells in it, ready for downstream analysis.   \n",
    "Data needed: 2um bin output, spatial folder from spaceranger (need to look into), high resolution morphology image (used example dataset in this notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"D:/binned_outputs/square_002um\"\n",
    "source_image_path = \"D:/Visium_HD_Mouse_Brain_tissue_image.tif\"\n",
    "spaceranger_image_path = \"D:/spatial\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "anndata.py (1758): Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "anndata.py (1758): Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 6296688 × 19059\n",
       "    obs: 'in_tissue', 'array_row', 'array_col'\n",
       "    var: 'gene_ids', 'feature_types', 'genome'\n",
       "    uns: 'spatial'\n",
       "    obsm: 'spatial'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading count matrix currently needs a bespoke loader function\n",
    "adata = b2c.read_visium(path, \n",
    "                        source_image_path = source_image_path, \n",
    "                        spaceranger_image_path = spaceranger_image_path\n",
    "                       )\n",
    "adata.var_names_make_unique()\n",
    "adata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar issue: data is sparse. Filtering - require gene to show up in 3 spots, require spots to have information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 6132629 × 18823\n",
       "    obs: 'in_tissue', 'array_row', 'array_col', 'n_counts'\n",
       "    var: 'gene_ids', 'feature_types', 'genome', 'n_cells'\n",
       "    uns: 'spatial'\n",
       "    obsm: 'spatial'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.pp.filter_genes(adata, min_cells=3)\n",
    "sc.pp.filter_cells(adata, min_counts=1)\n",
    "adata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bin2cell will perform a segmentation of both the H&E image and a gene expression representation of the data. When performing segmentation, the resolution of the input images is controlled via the mpp parameter.  \n",
    "mpp - microns per pixel (how many micrometers are captured in each pixel) (?) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cropped spatial coordinates key: spatial_cropped_150_buffer\n",
      "Image key: 0.3_mpp_150_buffer\n"
     ]
    }
   ],
   "source": [
    "# TODO: what is MPP?\n",
    "# working with HE image\n",
    "#likely to be closer to 0.3 for your data\n",
    "mpp = 0.3\n",
    "b2c.scaled_he_image(adata, mpp=mpp, save_path=\"stardist/he.tiff\") # image needs to be saved to the drive\n",
    "# if playing around with mpp, can do store=False\n",
    "\n",
    "# crops the image to area around the actual spatial grid present in the object, buffer of 150 pixels\n",
    "# new coordinates: .obsm[\"spatial_cropped_150_buffer\"]\n",
    "# can plot using sc.pl.spatial()\n",
    "# upon providing basis=\"spatial_cropped_150_buffer\" and img_key=\"0.5_mpp_150_buffer\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Working with IF image**  (?)  \n",
    "use b2c.scaled_if_image(). has a CHANNEL argument - point to index of DAPI signal in the channel list\n",
    "This creates a greyscale image, which should be segmented with StarDist's fluorescence model with syntax akin to what is done for the GEX representation later in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Issue: 2um bins have variability in width and height: will have a striped appearance, with some rows/cols having few transcripts than others.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIX: identify user-specified quantile (0.99) of total counts, and divide counts of spots in each row by the value. REPEAT for columns\n",
    "b2c.destripe(adata)\n",
    "\n",
    "# inspect changes\n",
    "#define a mask to easily pull out this region of the object in the future\n",
    "mask = ((adata.obs['array_row'] >= 1450) & \n",
    "        (adata.obs['array_row'] <= 1550) & \n",
    "        (adata.obs['array_col'] >= 250) & \n",
    "        (adata.obs['array_col'] <= 450)\n",
    "       )\n",
    "\n",
    "bdata = adata[mask]\n",
    "sc.pl.spatial(bdata, color=[None, \"n_counts\", \"n_counts_adjusted\"], color_map=\"OrRd\",\n",
    "              img_key=\"0.3_mpp_150_buffer\", basis=\"spatial_cropped_150_buffer\")\n",
    "\n",
    "# CANNOT PLOT DUE TO MEMORY ISSUES\n",
    "# adjusted count: multiply the per-spot factor by global quantile of count totals (?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can observe a sharper output than the one present in spaceranger (see website)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**H&E Segmentation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use StarDist's H&E model. Recommend to lower prob_thresh, image-resolution set by mpp.  \n",
    "Segmentation results turned into sparse matrix and stored in .npz - read using scipy.sparse.load_npz()  \n",
    "Sparse matrix's dimensions match the image's.  \n",
    "Also need to ensure gene expression bin grid is aligned with HE image - misalignment can be fixed by 10X loupe browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b2c.stardist(image_path=\"stardist/he.tiff\", \n",
    "             labels_npz_path=\"stardist/he.npz\", # define the path where segmentation label is saved\n",
    "             stardist_model=\"2D_versatile_he\", \n",
    "             prob_thresh=0.01 # probability threshold: A lower threshold (0.01) means StarDist will detect more nuclei, including lower-confidence ones.\n",
    "            )\n",
    "\n",
    "# MEMORY FAILURE, but will detect nucleis (?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next: load resulting cell calls into the object. (insert labels at each pixel)  \n",
    "need to inform the function of whether the image is based on array or spatial coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b2c.insert_labels(adata, \n",
    "                  labels_npz_path=\"stardist/he.npz\", # path to the labels generated by stardist\n",
    "                  basis=\"spatial\", \n",
    "                  spatial_key=\"spatial_cropped_150_buffer\", # the key where the cropped image is stored\n",
    "                  mpp=mpp, \n",
    "                  labels_key=\"labels_he\" # where segmentation labels will be stored\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize\n",
    "bdata = adata[mask]\n",
    "\n",
    "#the labels obs are integers, 0 means unassigned\n",
    "bdata = bdata[bdata.obs['labels_he']>0] # assigned labels\n",
    "bdata.obs['labels_he'] = bdata.obs['labels_he'].astype(str)\n",
    "\n",
    "# plot, see on website\n",
    "sc.pl.spatial(bdata, color=[None, \"labels_he\"], img_key=\"0.5_mpp_150_buffer\", basis=\"spatial_cropped_150_buffer\") # basis = spatial coordinate basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# another way to plot (visualize segmentation)\n",
    "#the label viewer wants a crop of the processed image\n",
    "#get the corresponding coordinates spanning the subset object\n",
    "crop = b2c.get_crop(bdata, basis=\"spatial\", spatial_key=\"spatial_cropped_150_buffer\", mpp=mpp) # retrieve spatial coordinates corresponding to bdata (cropped region)\n",
    "\n",
    "rendered = b2c.view_labels(image_path=\"stardist/he.tiff\", # overlay segmentation labels\n",
    "                           labels_npz_path=\"stardist/he.npz\", \n",
    "                           crop=crop\n",
    "                          )\n",
    "plt.imshow(rendered) # can overlay segmentation region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expanded Cell Identification**  \n",
    "Motivation: previous methods only identify nuclei, while a cell can be bigger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b2c.expand_labels(adata, \n",
    "                  labels_key='labels_he', \n",
    "                  expanded_labels_key=\"labels_he_expanded\"\n",
    "                 )\n",
    "# finds bins up to 2 bins away from labelled nucleus, joins to corresponding cell\n",
    "# can capture more bins, as saw on the webpage\n",
    "\n",
    "# Pro-tip: to customize expansion distance (not just 2 bins), can use algorithm = \"volume_ratio\" to get a custom distance based on its bin count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Detecting Missed Cells** (not sure relevance, not explored for now)  Results can be found on the original notebook  \n",
    "regions that have expression data but lack nuclei to seed a cell, or unusual cell shape.  \n",
    "FIX: segmentation on representation of total expression per bin (ONLY performs good on sparse tissue, not on dense ones)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Group bins into cells**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdata = b2c.bin_to_cell(adata, labels_key=\"labels_joint\", spatial_keys=[\"spatial\", \"spatial_cropped_150_buffer\"])\n",
    "# features sum of gene expriession in bins, means of array/spatial coords to represent cell centroids\n",
    "cell_mask = ((cdata.obs['array_row'] >= 1450) & \n",
    "             (cdata.obs['array_row'] <= 1550) & \n",
    "             (cdata.obs['array_col'] >= 250) & \n",
    "             (cdata.obs['array_col'] <= 450)\n",
    "            )\n",
    "\n",
    "ddata = cdata[cell_mask]\n",
    "sc.pl.spatial(ddata, color=[\"bin_count\", \"labels_joint_source\"], \n",
    "              img_key=\"0.5_mpp_150_buffer\", basis=\"spatial_cropped_150_buffer\")\n",
    "\n",
    "# can also identify source of labels (round 1, or round 2 after detection of missed cells)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
